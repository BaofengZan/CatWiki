
"""LangGraph ReAct Agent
1. ReAct å¾ªçŽ¯: Agent -> Tools -> Agent ... -> End
2. æ”¯æŒå¤šè½®æ£€ç´¢å’ŒæŽ¨ç†
3. åŠ¨æ€å¼•ç”¨æå–
"""

import logging
import json
from typing import Literal, List, Annotated

from langchain_core.messages import SystemMessage, BaseMessage, ToolMessage, HumanMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langchain_core.runnables import RunnableConfig

from app.schemas.graph_state import ChatGraphState
from app.services.vector_service import VectorService
from app.schemas.document import VectorRetrieveFilter
from app.core.prompts import SYSTEM_PROMPT, NO_RESULTS_MESSAGE

logger = logging.getLogger(__name__)

# æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶ï¼Œé˜²æ­¢ Agent æ— é™å¾ªçŽ¯ï¼ˆä»Žé…ç½®è¯»å–ï¼‰
from app.core.config import settings

MAX_ITERATIONS = settings.AGENT_MAX_ITERATIONS


# =============================================================================
# å·¥å…·å®šä¹‰
# =============================================================================


@tool
async def search_knowledge_base(query: str, config: RunnableConfig) -> str:
    """åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯ã€‚

    å½“ç”¨æˆ·çš„é—®é¢˜éœ€è¦äº‹å®žä¾æ®ã€æ–‡æ¡£æ”¯æŒæˆ–ä½ ä¸çŸ¥é“ç­”æ¡ˆæ—¶ï¼Œ**å¿…é¡»**ä½¿ç”¨æ­¤å·¥å…·ã€‚
    å¯ä»¥å¤šæ¬¡è°ƒç”¨æ­¤å·¥å…·ä»¥æŸ¥æ‰¾ä¸åŒæ–¹é¢çš„ä¿¡æ¯ã€‚

    Args:
        query: æœç´¢æŸ¥è¯¢è¯ã€‚åº”è¯¥æ˜¯é’ˆå¯¹ç‰¹å®šä¿¡æ¯çš„æ¸…æ™°é—®é¢˜ã€‚

    Returns:
        JSON æ ¼å¼çš„å­—ç¬¦ä¸²ï¼ŒåŒ…å«æœç´¢ç»“æžœåˆ—è¡¨ã€‚
        æ¯ä¸ªç»“æžœåŒ…å« 'content' (å†…å®¹æ‘˜å½•) å’Œ 'metadata' (åŒ…å« title, document_id ç­‰)ã€‚
    """
    # èŽ·å–ç«™ç‚¹ä¸Šä¸‹æ–‡
    site_id = config.get("configurable", {}).get("site_id")
    logger.info(f"ðŸ”§ [Tool] search_knowledge_base: query='{query}', site_id={site_id}")

    try:
        search_filter = VectorRetrieveFilter(site_id=int(site_id)) if site_id else None

        # æ‰§è¡Œæ£€ç´¢
        retrieved_docs = await VectorService.retrieve(
            query=query,
            k=5,
            threshold=0.3,
            filter=search_filter,
        )

        if not retrieved_docs:
            return NO_RESULTS_MESSAGE

        # æ ¼å¼åŒ–ç»“æžœ
        results = [
            {
                "content": doc.content,
                "metadata": {
                    "document_id": doc.document_id,
                    "title": doc.document_title,
                    "score": doc.score,
                    **doc.metadata,
                },
            }
            for doc in retrieved_docs
        ]

        return json.dumps(results, ensure_ascii=False)

    except Exception as e:
        logger.error(f"âŒ [Tool] Knowledge base search failed: {e}", exc_info=True)
        return f"æœç´¢çŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}"


# å·¥å…·åˆ—è¡¨
tools = [search_knowledge_base]


# =============================================================================
# è¾…åŠ©å‡½æ•°ï¼šå¼•ç”¨æå–
# =============================================================================


def extract_citations_from_messages(messages: List[BaseMessage], from_last_turn: bool = False) -> List[dict]:
    """ä»ŽåŽ†å²æ¶ˆæ¯çš„ ToolMessage ä¸­æå–å¼•ç”¨

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        from_last_turn: æ˜¯å¦ä»…æå–æœ€åŽä¸€è½®å¯¹è¯çš„å¼•ç”¨ (ä»Žæœ€åŽä¸€æ¡ HumanMessage å¼€å§‹)
    """
    citations = {}
    target_messages = messages

    if from_last_turn:
        # æ‰¾åˆ°æœ€åŽä¸€æ¡ HumanMessage çš„ç´¢å¼•
        last_human_idx = -1
        for i in range(len(messages) - 1, -1, -1):
            if isinstance(messages[i], HumanMessage):
                last_human_idx = i
                break
        
        if last_human_idx != -1:
            target_messages = messages[last_human_idx:]

    for msg in target_messages:
        if isinstance(msg, ToolMessage) and msg.name == "search_knowledge_base":
            try:
                content = msg.content if isinstance(msg.content, str) else json.dumps(msg.content)
                results = json.loads(content)
                
                if isinstance(results, list):
                    for doc in results:
                        meta = doc.get("metadata", {})
                        doc_id = meta.get("document_id")
                        if doc_id and doc_id not in citations:
                            citations[doc_id] = {
                                "id": str(doc_id),
                                "title": meta.get("title", "Unknown"),
                                "siteId": meta.get("site_id"),
                                "documentId": doc_id,
                                "score": meta.get("score"),
                            }
            except (json.JSONDecodeError, AttributeError):
                continue
            except Exception as e:
                logger.error(f"âŒ Error extracting citations: {e}")

    return list(citations.values())


# =============================================================================
# Agent å›¾æž„å»º
# =============================================================================


def create_agent_graph(checkpointer=None, model: ChatOpenAI = None):
    """åˆ›å»º ReAct Agent å›¾

    Args:
        checkpointer: å¯é€‰çš„ Checkpointer å®žä¾‹
        model: é…ç½®å¥½çš„ LLM å®žä¾‹ (å¿…é¡»æ”¯æŒ bind_tools)

    Returns:
        ç¼–è¯‘åŽçš„ StateGraph
    """
    if model is None:
        raise ValueError("Model must be provided to create_agent_graph")

    # 1. ç»‘å®šå·¥å…·åˆ°æ¨¡åž‹
    model_with_tools = model.bind_tools(tools)

    # 2. å®šä¹‰èŠ‚ç‚¹
    async def agent_node(state: ChatGraphState) -> dict:
        """Agent å†³ç­–èŠ‚ç‚¹"""
        logger.debug("ðŸ¤– [Agent] Thinking...")
        messages = state["messages"]

        # ç¡®ä¿ SystemPrompt å­˜åœ¨


        # æ³¨å…¥ System Prompt
        if not messages or not isinstance(messages[0], SystemMessage):
            messages = [SystemMessage(content=SYSTEM_PROMPT)] + list(messages)

        response = await model_with_tools.ainvoke(messages)
        return {"messages": [response]}

    # 3. æž„å»ºå›¾
    graph_builder = StateGraph(ChatGraphState)

    # å·¥å…·èŠ‚ç‚¹åŒ…è£…å™¨ï¼šé€’å¢žè¿­ä»£è®¡æ•° + æ£€æµ‹ç©ºç»“æžœ
    tool_node = ToolNode(tools)

    # è¿žç»­ç©ºç»“æžœç»ˆæ­¢é˜ˆå€¼ï¼ˆä»Žé…ç½®è¯»å–ï¼‰
    MAX_CONSECUTIVE_EMPTY = settings.AGENT_MAX_CONSECUTIVE_EMPTY

    async def tools_wrapper_node(state: ChatGraphState) -> dict:
        """å·¥å…·èŠ‚ç‚¹åŒ…è£…å™¨ï¼Œæ‰§è¡Œå·¥å…·å¹¶è¿½è¸ªè¿­ä»£è®¡æ•°å’Œç©ºç»“æžœ"""
        # è°ƒç”¨åŽŸå§‹å·¥å…·èŠ‚ç‚¹
        result = await tool_node.ainvoke(state)

        # é€’å¢žè¿­ä»£è®¡æ•°
        current_count = state.get("iteration_count", 0)
        result["iteration_count"] = current_count + 1

        # æ£€æµ‹å·¥å…·è¿”å›žæ˜¯å¦ä¸ºç©ºç»“æžœ
        consecutive_empty = state.get("consecutive_empty_count", 0)
        is_empty_result = False

        # æ£€æŸ¥æœ€åŽä¸€æ¡å·¥å…·æ¶ˆæ¯æ˜¯å¦ä¸ºç©ºç»“æžœ
        if result.get("messages"):
            last_tool_msg = result["messages"][-1] if result["messages"] else None
            if last_tool_msg:
                content = getattr(last_tool_msg, "content", "")
                # æ£€æµ‹ç©ºç»“æžœæ ‡å¿—
                if content == NO_RESULTS_MESSAGE or "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£" in content or content == "[]":
                    is_empty_result = True

        if is_empty_result:
            result["consecutive_empty_count"] = consecutive_empty + 1
            logger.debug(
                f"ðŸ”„ [Graph] Empty result, consecutive count: {result['consecutive_empty_count']}/{MAX_CONSECUTIVE_EMPTY}"
            )
        else:
            result["consecutive_empty_count"] = 0  # é‡ç½®

        logger.debug(f"ðŸ”„ [Graph] Iteration count: {result['iteration_count']}/{MAX_ITERATIONS}")
        return result

    # æ¡ä»¶è·¯ç”±å‡½æ•°ï¼šæ£€æŸ¥è¿­ä»£æ¬¡æ•°é™åˆ¶ + è¿žç»­ç©ºç»“æžœ
    def route_after_agent(state: ChatGraphState) -> Literal["tools", "__end__"]:
        """Agent åŽçš„è·¯ç”±å†³ç­–ï¼ŒåŒ…å«è¿­ä»£æ¬¡æ•°å’Œè¿žç»­ç©ºç»“æžœæ£€æŸ¥"""
        messages = state["messages"]
        last_message = messages[-1] if messages else None

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        if last_message and hasattr(last_message, "tool_calls") and last_message.tool_calls:
            # æ£€æŸ¥è¿­ä»£æ¬¡æ•°
            current_count = state.get("iteration_count", 0)
            if current_count >= MAX_ITERATIONS:
                logger.warning(f"âš ï¸ [Graph] Max iterations ({MAX_ITERATIONS}) reached, forcing end")
                return "__end__"

            # æ£€æŸ¥è¿žç»­ç©ºç»“æžœ
            consecutive_empty = state.get("consecutive_empty_count", 0)
            if consecutive_empty >= MAX_CONSECUTIVE_EMPTY:
                logger.warning(
                    f"âš ï¸ [Graph] {MAX_CONSECUTIVE_EMPTY} consecutive empty results, stopping early"
                )
                return "__end__"

            return "tools"

        return "__end__"

    graph_builder.add_node("agent", agent_node)
    graph_builder.add_node("tools", tools_wrapper_node)

    # 4. å®šä¹‰è¾¹
    graph_builder.add_edge(START, "agent")

    # æ¡ä»¶è¾¹: Agent -> (Tools | END)ï¼ŒåŒ…å«è¿­ä»£æ¬¡æ•°æ£€æŸ¥
    graph_builder.add_conditional_edges(
        "agent",
        route_after_agent,
    )

    # å¾ªçŽ¯è¾¹: Tools -> Agent
    graph_builder.add_edge("tools", "agent")

    return graph_builder.compile(checkpointer=checkpointer)


# =============================================================================
# è¾…åŠ©å‡½æ•°
# =============================================================================



